{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function Win32Window._get_window_proc.<locals>.f at 0x000001D1C41080D0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\37103\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\", line 651, in f\n",
      "    def f(hwnd, msg, wParam, lParam):\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "observation = env.reset()\n",
    "for _ in range(1000):\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(keras.Model):\n",
    "    '''\n",
    "    策略网络，生成动作的概率分布\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.data = []\n",
    "        \n",
    "        self.fc1 = layers.Dense(128, kernal_initializer='he_normal')\n",
    "        self.fc2 = layers.Dense(2, kernal_initializer='he_normal')\n",
    "        \n",
    "        self.optimizer = optimizers.Adam(lr=learning_rate)\n",
    "    \n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        x = tf.nn.relu(self.fc1(inputs))\n",
    "        x = tf.nn.softmax(self.fc2(x), axis=1)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def put_data(self, item):\n",
    "        self.data.append(item)\n",
    "    \n",
    "    \n",
    "    def train_net(self, tape):\n",
    "        R = 0\n",
    "        for r, log_prob in self.data[::-1]:\n",
    "            R = r + gamma * R\n",
    "            loss = -log_prob * R\n",
    "            with tape.stop_recording():\n",
    "                grads = tape.gradient(loss, self.trainable_variables)\n",
    "                self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        \n",
    "        self.data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd065965f99a7c7e05bf585cd1d20bd7d14ab39020bb20f433661cac236024d8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
